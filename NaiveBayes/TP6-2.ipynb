{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1461,
     "status": "ok",
     "timestamp": 1608475169023,
     "user": {
      "displayName": "Daniel Benedí García",
      "photoUrl": "",
      "userId": "15032925353635224754"
     },
     "user_tz": -60
    },
    "id": "JsPaONJSA3F2"
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Imports\n",
    "######################################################\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1608475197264,
     "user": {
      "displayName": "Daniel Benedí García",
      "photoUrl": "",
      "userId": "15032925353635224754"
     },
     "user_tz": -60
    },
    "id": "6FFjiZE_WXFh"
   },
   "outputs": [],
   "source": [
    "def read_folder(folder):\n",
    "    mails = []\n",
    "    file_list = glob.glob(folder)  # List mails in folder\n",
    "    num_files = len(file_list)\n",
    "    for i in range(0, num_files):\n",
    "        i_path = file_list[i]\n",
    "        i_file = open(i_path, 'rb')\n",
    "        i_str = i_file.read()\n",
    "        i_text = i_str.decode('utf-8', errors='ignore')  # Convert to Unicode\n",
    "        mails.append(i_text)  # Append to the mail structure\n",
    "        i_file.close()\n",
    "    return mails\n",
    "\n",
    "\n",
    "def load_enron_folders(datasets):\n",
    "    path = './dataset/'\n",
    "    ham = []\n",
    "    spam = []\n",
    "    for j in datasets:\n",
    "        ham  = ham  + read_folder(path + 'enron' + str(j) + '/ham/*.txt')\n",
    "        spam = spam + read_folder(path + 'enron' + str(j) + '/spam/*.txt')\n",
    "    num_ham  = len(ham)\n",
    "    num_spam = len(spam)\n",
    "    print(\"mails:\", num_ham+num_spam)\n",
    "    print(\"ham  :\", num_ham)\n",
    "    print(\"spam :\", num_spam)\n",
    "\n",
    "    mails = ham + spam\n",
    "    labels = [0]*num_ham + [1]*num_spam\n",
    "    mails, labels = shuffle(mails, labels, random_state=0)\n",
    "    return mails, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords():\n",
    "    stopwords = []\n",
    "    path = './NLTKstopwords.txt'\n",
    "    file = open(path, 'r')\n",
    "    stopwords = file.read().splitlines()\n",
    "    file.close()\n",
    "    print(\"stopwords: \", len(stopwords))\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KfoldCrossValidation(X, Y, stopwords, K):\n",
    "    Y = np.array(Y)\n",
    "    extractors = [CountVectorizer(ngram_range=(1,1)),\n",
    "                  CountVectorizer(ngram_range=(1,2)),\n",
    "                  CountVectorizer(ngram_range=(1,1), stop_words=stopwords),\n",
    "                  CountVectorizer(ngram_range=(1,2), stop_words=stopwords),\n",
    "                  CountVectorizer(ngram_range=(1,1), stop_words='english'),\n",
    "                  CountVectorizer(ngram_range=(1,2), stop_words='english')]\n",
    "    types = ['Multinomial', 'Bernoulli']\n",
    "    alphas = [0.01,0.05,0.1,0.25,0.5,0.75,1,2,5,10,25,50,100]\n",
    "    \n",
    "    print(\"Generating classifiers...\")\n",
    "    classifiers = []\n",
    "    for t in types:\n",
    "        for alpha in alphas:\n",
    "            if t == 'Multinomial':\n",
    "                classifiers.append(MultinomialNB(alpha=alpha))\n",
    "            elif t == 'Bernoulli':\n",
    "                classifiers.append(BernoulliNB(alpha=alpha))\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    res = []\n",
    "    best_errV = np.inf\n",
    "    best_model = 0\n",
    "    for extractor in extractors:\n",
    "        X_train = extractor.fit_transform(X)\n",
    "        for clf in classifiers:\n",
    "            err_T = 0\n",
    "            err_V = 0\n",
    "            kf = KFold(n_splits=K)\n",
    "            for Xindex, Vindex in kf.split(X_train, Y):\n",
    "                Xtrain, Xvalidation = X_train[Xindex], X_train[Vindex]\n",
    "                Ytrain, Yvalidation = Y[Xindex], Y[Vindex]\n",
    "                clf.fit(Xtrain, Ytrain)\n",
    "                err_T += 1-clf.score(Xtrain, Ytrain)\n",
    "                err_V += 1-clf.score(Xvalidation, Yvalidation)\n",
    "            err_T = err_T/K\n",
    "            err_V = err_V/K\n",
    "            if err_V < best_errV:\n",
    "                print(\"New best: \", extractor, clf, err_V)\n",
    "                best_model = (extractor, clf)\n",
    "                best_errV = err_V\n",
    "            res.append( (extractor, clf, err_T, err_V) )\n",
    "\n",
    "    return res, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hj4XoPeWZXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "------Loading train and validation data--------\n",
      "mails: 27716\n",
      "ham  : 15045\n",
      "spam : 12671\n",
      "--------------Loading Test data----------------\n",
      "mails: 6000\n",
      "ham  : 1500\n",
      "spam : 4500\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading files...\")\n",
    "\n",
    "print(\"------Loading train and validation data--------\")\n",
    "mails, y = load_enron_folders([1,2,3,4,5])\n",
    "\n",
    "print(\"--------------Loading Test data----------------\")\n",
    "mails_test, y_test = load_enron_folders([6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Loading Stopwords----------------\n",
      "stopwords:  127\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------Loading Stopwords----------------\")\n",
    "stopwords = load_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1608466711848,
     "user": {
      "displayName": "Daniel Benedí García",
      "photoUrl": "",
      "userId": "15032925353635224754"
     },
     "user_tz": -60
    },
    "id": "I08qLVgMWbPg",
    "outputId": "1ece8484-59f2-4f6a-eb98-6e2b5d9d1943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Initializing BOW structure-----\n",
      "Train size:  3260159\n",
      "Test size:  726926\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Initializing BOW structure-----\")\n",
    "vectorizer  = CountVectorizer(ngram_range=(1, 1))  # Initialize BOW structure\n",
    "X = vectorizer.fit_transform(mails)                # BOW with word counts\n",
    "X_test = vectorizer.transform(mails_test)          # BOW with word counts\n",
    "print(\"Train size: \",X.getnnz())\n",
    "print(\"Test size: \",X_test.getnnz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- K-fold CrossValidation -----\n",
      "Generating classifiers...\n",
      "Starting training...\n",
      "New best:  CountVectorizer() MultinomialNB(alpha=0.01) 0.011906499598182818\n",
      "New best:  CountVectorizer() MultinomialNB(alpha=0.05) 0.01187043107032284\n",
      "New best:  CountVectorizer(ngram_range=(1, 2)) MultinomialNB(alpha=0.01) 0.0076851476544783194\n",
      "New best:  CountVectorizer(ngram_range=(1, 2),\n",
      "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', 'your', 'yours', 'yourself',\n",
      "                            'yourselves', 'he', 'him', 'his', 'himself', 'she',\n",
      "                            'her', 'hers', 'herself', 'it', 'its', 'itself',\n",
      "                            'they', 'them', 'their', 'theirs', 'themselves',\n",
      "                            'what', ...]) MultinomialNB(alpha=0.01) 0.007649046585543084\n",
      "(CountVectorizer(ngram_range=(1, 2),\n",
      "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', 'your', 'yours', 'yourself',\n",
      "                            'yourselves', 'he', 'him', 'his', 'himself', 'she',\n",
      "                            'her', 'hers', 'herself', 'it', 'its', 'itself',\n",
      "                            'they', 'them', 'their', 'theirs', 'themselves',\n",
      "                            'what', ...]), MultinomialNB(alpha=0.01))\n"
     ]
    }
   ],
   "source": [
    "print(\"----- K-fold CrossValidation -----\")\n",
    "Results, Classifier = KfoldCrossValidation(mails, y, stopwords, 5)\n",
    "print(Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-5f7efbff8a53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmails_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mClassifier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[1;34m\"\"\"Calculate the posterior log probability of the samples X\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0m\u001b[0;32m    778\u001b[0m                 self.class_log_prior_)\n\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "x_test = Classifier[0].fit_transform(mails_test)\n",
    "Classifier[1].score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1403738 6000\n"
     ]
    }
   ],
   "source": [
    "print(x_test.getnnz(), len(y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNG+UV7Y1bc11iprH6VnQxo",
   "collapsed_sections": [],
   "mount_file_id": "1tBUVdyR-EE2Xa3LYzPtn1FsFA9lTwnix",
   "name": "TP6-2.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
